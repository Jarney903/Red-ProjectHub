<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:300,400,700" rel="stylesheet">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous" />

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
        integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />

    <!-- Custom styles for this template -->
    <link href="static/styles/style.css" rel="stylesheet" />
    <title>Red Group | Final Project</title>
</head>

<body>

    <header>
        <div class="wave">
            <div class="container header-container">
                <h1 class="name">Prediction of Normal Butane Volume</h1>
                <h3 class="subtitle text-center">Money Saver Team.</h3>
                <!-- <./student.png" class="boy" alt="boy image" /> -->
            </div>
        </div>
        <div class="wave-svg">
            <svg xmlns="http://www.w3.org/2000/svg" fill="#fff" opacity="1" width="100%" height="80"
                preserveAspectRatio="none" viewBox="0 0 1600 200">
                <path d="M-8,95.3C-8,95.3,189,2,398,2s604,184.7,800,184.7s412-91.4,412-91.4V271H-8V95.3z" />
                <path
                    d="M1610,95.3c0,0-216,80-412,80c-98,0-245.8-40.5-395.1-80.9c149.4,46.2,297.1,92.3,395.1,92.3C1394,186.7,1610,95.3,1610,95.3z" />
            </svg>
        </div>
    </header>

    <section class="container">
        <h1 class="title">
        </h1>
        <h3 class="subtitle">Our goal is save money to the refineries utilizing plant data from multiple unit assets to develop machine learning methods to predict "live" volume percentage of N-Butane build up in the refineries.
            A penny
            saved
            is a penny
            earned. </h3>
    </section>


    <section class="container skill-container">
        <div class="row">
            <div class="col-md-10 offset-md-1">

                <div class="row text-center">
                    <div class="col">
                        <div class="skill-bar-title">
                            <i class="fab fa-html5 fa-3x"></i>
                            <p>HTML5</p>
                        </div>
                    </div>

                    <div class="col">
                        <div class="skill-bar-title">
                            <i class="fab fa-css3-alt fa-3x"></i>
                            <p>CSS3</p>
                        </div>
                    </div>
                    <div class="col">
                        <div class="skill-bar-title">
                            <i class="fab fa-js-square fa-3x"></i>
                            <p>JavaScript</p>
                        </div>
                    </div>
                    <div class="col">
                        <div class="skill-bar-title">
                            <i class="fab fa-node fa-3x"></i>
                            <p>NodeJS</p>
                        </div>
                    </div>
                    <div class="col">
                        <div class="skill-bar-title">
                            <i class="fab fa-git fa-3x"></i>
                            <p>Git</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </section>

    <div class="wave-svg-color">
        <svg xmlns="http://www.w3.org/2000/svg" fill="#328eff" opacity="1" width="100%" height="80"
            preserveAspectRatio="none" viewBox="0 0 1600 200">
            <path d="M-8,95.3C-8,95.3,189,2,398,2s604,184.7,800,184.7s412-91.4,412-91.4V271H-8V95.3z" />
            <path
                d="M1610,95.3c0,0-216,80-412,80c-98,0-245.8-40.5-395.1-80.9c149.4,46.2,297.1,92.3,395.1,92.3C1394,186.7,1610,95.3,1610,95.3z" />
        </svg>
    </div>

    <section class="container-color">
    </section>
    <section class="container">
        <div class="card custom-card">
            <div class="card-body">
                <span class="card-icon">
                    <i class="fas fa-code"></i>
                </span>

                <h3 class="card-title">More about the problem</h3>
                <p class="card-text">Excess N-Butane accumulates in the Tower A recycle stream and essentially dilutes 
                                    the isobutane content resulting in unfavorable reaction conditions, effects reaction
                                    quality, and I:O ratio (Isobutane : Olefin). Lab sample frequency periods being too far apart (12 hours) along with subtle N-Butane accumulation manifests in a way that is difficult for humans to recognize quickly or effectively. However, N-Butane must be removed in such a way that there is a balance on the reaction, separation section, and in the product stream. The more N-Butane that leaves the unit, the more isobutane also leaves the unit, therefore a balance must take place in the unit between the two species to keep N-Butane manageable while limiting Isobutane loses.. </p>
                <h5 class="card-title">
                    Technologies We Used:
                </h5>
                <p class="card-text">
                    Github, Python, Jupyter Notebook, Google Colab, Google docs, Machine Learning,
                    Mongo DB, Modeling, Excel, PostgreSQL, Pgadmin, Quick Data Base Diagram, Flask,
                    HTML, CSS, Tableau, AWS, Pandas, Extract-Transform-Load (ETL)

                </p>
            </div>
        </div>
    </section>





    <!-- TIMELINE -->
    <section class="container">
        <h1 class="title">Workflow Process</h1>
        <h3 class="subtitle">These are the steps we took to run this analysis.</h3>
    </section>


    <div class="container">
        <div id="timeline">
            <div class="timeline-item">
                <div class="timeline-icon">
                    <i class="fas fa-star fa-align"></i>

                </div>
                <div class="timeline-content">
                    <h2 style="margin-bottom: 0.5em">ETL and EDA</h2>
                    <p>
                        The exploratory data analysis process began with checking the raw data for non-numerical values. We found that there were a few text strings: "Bad", "Bad Input", "Error", and "I/O Timeout". All values across the datasets were object types, and we wanted to convert those to float types. The text strings were preventing the whole dataset from being converted with minimal code. So, we replaced these text strings with NaN values, and dropped them. Then we did a full conversion, and generated summary statistics to get an idea of the spread of the data values. We noted multiple values that made no sense (like percent values that fell outside 0-100) and marked them for removal.
                    </p>
                    <p>
                        During the EDA process we also saw that some datetimes were strange. Data was collected at 2 times every day: hour 6 and hour 13, and never at any minute besides 00. A significant chunk of the data was collected at arbitrary datetimes, and this was concerning. After some discussion, we realized that the dates that were strange fell under a period of turnaround for the plant, meaning that the plant itself was shut down and all the data collected in the period was invalid. We marked those datetimes for removal during the data cleaning process.
                    </p>
                    <p>
                        We also went ahead and calculated some feature importances, feature coefficients, and correlations to understand the relationships of the features among each other and with different model types. The feature importance functions such as model.coef_ and model.feature_importances_, along with naitive process knowlege of team group members, allowed for a systematic ranking of features. Though 54 of the original 56 features were left in the model, the feature importance ranking is a valuable output and will be used to further tune the model outside of the class project end date.
                    </p>
                    <a href="https://github.com/Jarney903/Red-ProjectHub/tree/main/ETL" class="btn"><i class="fab fa-github"></i> Code</a>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-icon">
                    <i class="fas fa-star fa-align"></i>

                </div>
                <div class="timeline-content right">
                    <h2 style="margin-bottom: 0.5em">PostgreSQL Database</h2>
                    <p>
                        An extensive ETL Phase for cleaning data, removing outliers, and finding feature importance was completed. The 5 cleaned datasets were then uploaded to PostgreSQL as 5 seperate table, with primary keys of Date, as each date represents a unique data field, shared by all datasets. The 5 tables were then merged using the SQL inner-join command as one table named project_data. T
                    </p>
                    <a href="https://github.com" class="btn"><i class="fab fa-github"></i> Code</a>
                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-icon">
                    <i class="fas fa-star fa-align"></i>
                </div>
                <div class="timeline-content">
                    <h2 style="margin-bottom: 0.5em">Machine Learning</h2>
                    <p>
                        Twelve (12) provisional machine learning models were created and published on the Model Testing Branch. These models were used as stand-ins for the final machine learning model and have helped the team determine the best methods for cleaning and determining feature importances. These provisional models have also helped guide the descision making in selecting the best model library to use for the final project deliverable. 
                    </p>
                    <p>
                        After testing the cleaned and joined data through the following models, Linear Regression, Logistic Regression, Random Forrest, and Support Vector Machine, the model selected was SK Learn's Linear Regression model. This model was chosen because the output (y_predict) was more acurate, and an actual representation of the N-Butane Vol%, rather than a binary grouping prediction is output. 
                    </p>
                    <a href="https://github.com" class="btn"><i class="fab fa-github"></i> Code</a>

                </div>
            </div>

            <div class="timeline-item">
                <div class="timeline-icon">
                    <i class="fas fa-star fa-align"></i>

                </div>
                <div class="timeline-content right" :after>
                    <h2 style="margin-bottom: 0.5em">Dashboard</h2>
                    <p>
                        To display the results of our analysis, we chose to build a Flask app, using Python and connecting to the PostgreSQL Database we made to hold both our raw data, clean data, and finally our Linear Regression results.
                    </p>
                    <a href="https://github.com" class="btn"><i class="fab fa-github"></i> Code</a>
                </div>
            </div>
        </div>
    </div>



    <!--Results Title-->
    <section class="container">
        <div class="header-container">
            <h1 class ='title'   style='background-color:#328eff;  padding:30px;  border:1px solid #328eff; color: white;' >N-Butane Prediction Model Results</h1>
                <h4>Linear Regression</h4>
            <h3 class="education-item">Snapshot of Predictions versus Actual values</h3>
            <table style = "width:50%">
                <tr>
                  <th>Predictions</th>
                  <th>Actual</th>
                </tr>
                {% for row in pj_results_15 %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                </tr>
                {% endfor %}
              </table> 
            <h3 class="space-item">Metrics of Project Data</h3>
            <table style = "width:50%; padding-bottom: 30px;">
                <tr>
                  <th>Data</th>
                  <th>R2_Score</th>
                  <th>Mean_Error</th>
                  <th>Mean_Absolute_Error</th>
                  <th>Estimated_Variance_Score</th>
                </tr>
                {% for row in project_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                </tr>
                {% endfor %}
              </table> 
    </section>
    

    <section>
        <div class="header-container">
            <h2 class='title' style="padding: 40px">Summary of Results</h2>
            <p style="font-size: 20px; width: 1000px; padding: 20px;">The final results of the linear regression run on the combined project data (Towers A, B, C and Reactors) gave us an R2_Score of 0.435 and a Mean Error of 2.594 (Mean Absolute Error and Estimated Variance Score are also given for those who are interested, however the R2 Score and Mean Error are our primary metrics). 
                The R2 Score tells us the amount of variation in the output variable from the input variables. For us, this means that the output variable (N-Butane percentage level) and our input data from the towers and reactors, are correlated at 43.5% through our Linear Regression Model. 
                In terms of the predictions, our predictive values tend to be within 2.594 percentage points of the actual value. However, due to the way that the data was merged, many data points were lost. 
                I recommend a rework of the ETL and cleaning process to preserve as many mergable data points as possible for further model testing. 
                Our combined dataset had just under 1000 data points, making our machine learning analysis much weaker than it would have been. 
                In order to put this into perspective, we also ran the same model on a more limited merged dataset that focused on Tower A and the output only.</p>
            <table style = "width:50%;">
                <tr>
                    <th>Data</th>
                    <th>R2_Score</th>
                    <th>Mean_Error</th>
                    <th>Mean_Absolute_Error</th>
                    <th>Estimated_Variance_Score</th>
                </tr>
                {% for row in ta_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                </tr>
                {% endfor %}
            </table>
            <p style="font-size: 20px; width: 1000px; padding: 20px;">
                In comparison, the isolated Tower A and Lab linear regression ran with 2537 data points, and shows a R2 Score of 0.596 and a Mean Error of 2.724. 
                This tells us that the correlation between Tower A data and the N-Butane Levels are about 60% correlated. 
                However, the predictive values are still between 2 and 3 percentage points off from the actual values, showing that although our correlations are stronger, the Mean Error is more or less the same.
                Below is a table of the metrics of different combined datasets.
                Project Data holds all towers and reactors as inputs. Lab_rx holds only the reactor data as inputs. Towers_data holds all the towers' data as inputs. Finally, each tower is examined in isolation. The Data points of these datasets are also given to show efficacy of the model.
            </p>
            <h4 style="padding: 20px;">Metrics For All Datasets</h4>
            <table style = "width:50%;">
                <tr>
                    <th>Data</th>
                    <th>R2_Score</th>
                    <th>Mean_Error</th>
                    <th>Mean_Absolute_Error</th>
                    <th>Estimated_Variance_Score</th>
                    <th>Data Points/Rows</th>
                </tr>
                {% for row in project_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                    <td>992</td>
                </tr>
                {% endfor %}
                {% for row in rx_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                    <td>3953</td>
                </tr>
                {% endfor %}
                {% for row in towers_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                    <td>1022</td>
                </tr>
                {% endfor %}
                {% for row in ta_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                    <td>2537</td>
                </tr>
                {% endfor %}
                {% for row in tb_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                    <td>1412</td>
                </tr>
                {% endfor %}
                {% for row in tc_metrics %}
                <tr>
                    <td>{{row[0]}}</td>
                    <td>{{row[1]}}</td>
                    <td>{{row[2]}}</td>
                    <td>{{row[3]}}</td>
                    <td>{{row[4]}}</td>
                    <td>5246</td>
                </tr>
                {% endfor %}
            </table>
        </div>
    </section>
    
    <section>
        <div class="header-container">

        </div>
    </section>
    
    <section class="container">
        <div class="header-container">
            <h1 class ='title'   style='background-color:#328eff;  padding:30px;  border:1px solid #328eff; color: white; margin-top: 2.5em;' >Conclusions</h1>
            <p style="font-size: 20px; width: 1000px; padding: 20px;">
                The purpose of this analysis was to begin the production of a model that could accurately (within 2 percentage points at most) predict levels of N-Butane being recycled back into the alkylation unit based on the data taken from the reactors and the processing towers.
                We achieved, with our beginner skills, a Mean Error between 2 and 3 percentage points, which is above the acceptable accuracy we wanted. 
                That being said, the model itself may need some more skilled tweaking, and the ETL process should be refined. Once those two avenues have been exhausted, I think it would be prudent to rerun the model on the newly cleaned and organized datasets.
                In terms of testing other types of models, we believe that Neural Networks for Regression may be an option. Classification models are unlikely to provide useful results, since the outputs are not binary. 
                While the outputs could be encoded like a binary system, the decision making for that is beyond this teams understanding, and would require more knowledge of the alkylation units and processes.
                It is also possible that there are factors beyond our input features that have an effect on the levels of N-Butane being recycled/built up in the alkylation units. 
                Another strategy we could implement in the future to improve the Mean Error score of our model could be to project reasonable data in place of Null or Bad data, reducing the number of data rows we have to scrap.
                Ultimately, while we did not meet the standard of accuracy for our interests, we do believe we have made a solid start into developing a model appropriate to addressing the N-Butane prediction problem.
            </p>
        </div>
    </section>

    <!-- EDUCATION -->
    <section class="container education-container">
        <h1 class="title">Education </h1>
        <article class="education-item">
            <h3 class="subtitle">Vanderbilt University</h3>
            <span class="text-muted">Data Analysis Bootcamp| March 2022 - Aug 2022</span>
        </article>
        <hr />
 



    </section>

    <!-- AVAILABLE FOR WORK -->
    <section class="container-color">
        <div class="container">
            <h1 class="title">We are available for future projects!
            </h1>
            <h3 class="subtitle">Actively contributing to new projects and seeking a full-time role in a fast-paced,
                agile environment. Get in touch!</h3>
        </div>
    </section>

    <!-- Contact Footer -->
    <section class="container-dark">
        <div class="container">
            <h1>Contact Us</h1>
            <h2>Anna Day</h2>
            <h3 class="intro subtitle">
                <a href="www.linkedin.com/in/anna-day-b48336233" class="social-icon"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/AnnaKDay" class="social-icon"><i class="fab fa-github"></i></a>
                <a href="mailto:<annaday9999@gmail.com>" class="social-icon"><i class="fas fa-envelope"></i></a>
            </h3>
            <hr/>
            <h2>John Brenton Arney</h2>
            <h3 class="intro subtitle">
                <a href="https://linkedin.com/in" class="social-icon"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/Jarney903" class="social-icon"><i class="fab fa-github"></i></a>
                <a href="mailto:<YOUREMAIL>" class="social-icon"><i class="fas fa-envelope"></i></a>
            </h3>
            <hr/>
            <h2>Eva Hawkins</h2>
            <h3 class="intro subtitle">
                <a href="https://www.linkedin.com/in/eva-hawkins-a9b333147/" class="social-icon"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/ehawkins0631" class="social-icon"><i class="fab fa-github"></i></a>
                <a href="mailto:<YOUREMAIL>" class="social-icon"><i class="fas fa-envelope"></i></a>
            </h3>
        </div>
    </section>

    <footer>
        <div class="container">
            Anna Day, John Brenton Arney, Eva Hawkins &copy; Aug 2022 |
        </div>
    </footer>


    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js"
        integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut"
        crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js"
        integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k"
        crossorigin="anonymous"></script>
    <script src="static/js/app.js"></script>
</body>

</html>
